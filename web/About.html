<!doctype html>
<html lang="ja">
<head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="A layout example with a side menu that hides on mobile, just like the Pure website.">

    <title>About</title>




<link rel="stylesheet" href="css/layouts/src.css">
<link rel="stylesheet" href="css/layouts/src_new.css">





    <!--[if lte IE 8]>
        <link rel="stylesheet" href="css/layouts/side-menu-old-ie.css">
    <![endif]-->
    <!--[if gt IE 8]><!-->
        <link rel="stylesheet" href="side-menu.css">
    <!--<![endif]-->







</head>
<body>
<div id="layout">
    <!-- Menu toggle -->
    <a href="#menu" id="menuLink" class="menu-link">
        <!-- Hamburger icon -->
        <span></span>
    </a>

    <div id="menu">
        <div class="pure-menu">
            <a class="pure-menu-heading" href="Top.html">Srobot</a>

            <ul class="pure-menu-list">
                <li class="pure-menu-item"><a href="About.html" class="pure-menu-link">About</a></li>
                <li class="pure-menu-item"><a href="Projects.html" class="pure-menu-link">Projects</a></li>
                <li class="pure-menu-item"><a href="Member.html" class="pure-menu-link">Member</a></li>
                <li class="pure-menu-item"><a href="Join.html" class="pure-menu-link">Join</a></li>
                <li class="pure-menu-item"><a href="Contact.html" class="pure-menu-link">Contact</a></li>
            </ul>
        </div>
    </div>

    <div id="main">
        <div class="header">
            <h1>About</h1>
            <h2>研究理念</h2>
        </div>

        <div class="content">
            <div class="pure-g">
                <div class="pure-u-1-1">
                  <img class="pure-img-responsive" src="photo/1.png" alt="Nao1">

                </div>
            </div>
            <p><strong>ソーシャブルな存在としてのロボット</strong></p>

<p><em>&quot;Making robots more acceptable..&quot; by Prof. Gordon Cheng（ICS／TUM）</em></p>

<p>常時ネットワークに接続された次世代のロボットは，自ら M2M（Machine to Machine）コミュニケーション，M2S（Machine to Service）コミュニケーションを駆使する存在として，あるものはユビキタス情報サービスのアクターとして人々と共存し，またあるものは人の身体拡張を支援する，より社会的な存在となります．我々はこうしたロボットをソーシャブルロボット（Sociable Robot）と呼びます．社会性を備えたロボット，すなわち，ロボット同士，機械，情報サービス，そして人と能動的に繋がるロボットです．ソーシャブルロボットには，次のような機能が求められます．</p>

<ul>
<li>
異種ロボット間のクラウド型協調・連携機能（Cloud Network Robotics）
</li>
<li>
生体神経網と同等の高精度知覚・認知処理機能（Sentient &amp; Cognitive Robotics）
</li>
<li>
豊かな表情での社会的・情動的インタラクション機能（Affective &amp; Interactive Robotics）
</li>
</ul>

<p>第一の要件「クラウド型協調・連携」は言わば，ヘテロジニアスなロボット間連携・協調動作を実現するアーキテクチャです．多種多様なロボットのそれぞれが提供可能なサービスに関する情報を相互に共有することで，タスクに応じたコミュニティを自律的かつ臨機応変に形成し，様々なクラウドサービスとも連携しながら，ゴールの達成を目指します．本研究プロジェクトでは，ソーシャブルロボットの基本機能として適用可能な，異種ロボット同士，さらには多種多様な情報サービスとのクラウド型協調・連携を可能にするクラウドネットワークロボット間連携フレームワークを開発します．</p>

<p>高度な社会性（Sociality）を備えたロボットにとって，ロボット自身が持つ知覚・認知能力は，人とのインタラクションの中でロボットの所作を決定する重要なファクターになります．第二の要件「高精度知覚・認知処理」に関しては，TUM / ICSでの Hex-o-Skin プロジェクトとの共同研究プロジェクトが進行中です．TUM / ICS Hex-o-Skin プロジェクトで開発が進むパッド型人工皮膚は，高度にモジュール化されており，皮下受容細胞に相当する触感センサ（近接，直接の2種），温感センサ，さらには運動感覚，平衡感覚を受容する高精度な動きセンサを備え，複数のパッドを連接して使用することで，人間の皮膚に近いレベルでの実世界情報収集と状況認識を可能としています．本研究プロジェクトでは，これらの皮膚感覚に加え，人とロボット（H2R）のインタラクションにおけるロボットの知覚・認知処理の中でも特に重要と考えられる，視覚（画像知覚・認知）に着目し，視覚による対話相手の情動取得，すなわち人の感情変化の取得機構を議論します．</p>

<p>対話相手の情動認識機能は，第三の要件「社会的・情動的インタラクション」の実現に不可欠なものです．本研究プロジェクトでは，TUM / ICS のチームと共同で，生体神経網をモデルとしたスケーラブルな知覚神経ネットワークおよび認知機能を研究・開発します．他のロボットとの情報共有や，情動取得に関する視覚からのアプローチと併せて，センサクラウドとの連携も可能な，ソーシャブルロボット広域知覚神経網・認知システムとしての完成を目指しています．</p>

<p>さらに第三の要件「社会的・情動的インタラクション」に関しては，情動を含む周囲と相手の状況を理解した上での，多対多 H2R，さらには R2R（ロボット同士）インタラクションの実現手法を議論します．私たちはこれまでにも，「共感するロボット」「遠隔アイスブレーキング支援ロボット」等を実装し，様々な利用シーンでの多対多 R2H インタラクションを例示してきましたが，本研究プロジェクトでは，多対多 R2H インタラクションの実現に向けた会話コンテクスト管理・制御機構を提案し，情動的インタラクション実現の一例として，上述の視覚による情動認識機構を応用した，会話の中での身体的表現力増強ロボットの提案を目指します．</p>

<p>現在，上記要件を満たすソーシャブルロボットシステムの適用例として，企業と共同で，情動的コミュニケーション支援ロボットをベースとした，ALS 患者等四肢麻痺患者向けのコミュニケーション支援ロボットに関する研究・開発プロジェクトが進行中です．同プロジェクトは，現在も足立区のデイケア施設での実証実験が進んでおり，ここでの成果は，ソーシャブルロボットの実社会応用として大きく期待されています．</p>

<hr />

<p><strong>IoT から Sociable Things の世界へ</strong></p>

<p>前述のヒューマノイド型のコミュニケーションロボットやパーソナルロボットをターゲットとして提案した技術を，より細粒度なモノやロボットに適用することで，次世代IoT環境の構築が可能となります．私たちはこれを，Sociable Things と呼んでいます．個々の Sociable Thing が高機能である必要はありません．ユーザの挙動や情動を理解し，共有し，それぞれのモノとしての機能を少しだけユーザに寄り添う形で提供する，そんなモノたちのコミュニティです．</p>

<p>例えば，ソーシャブルなゴミ箱（Sociable Trashbox）は，ゴミを投げようとしているユーザを検知し，その方向に筐体を傾けます．ゴミを捨てようとしているユーザを発見し，自ら近づいて行ってもいいでしょう．物体の移動は人間の注意を引きますし，物体が傾く動作は人間における感謝を表すための「会釈」というボディランゲージに似ているとも言えます．ユーザが子どもであれば，子どもたちはゴミ箱そのものの動きに関心を寄せるでしょうし，会釈のように見える動作には愛着を覚えることもあるでしょう．結果として，「見逃されがちなゴミ箱やゴミを捨てるという行為に興味や楽しさを覚える」といった，意識の変化を見ることができるかもしれません．このように，Sociable Things には，人間に物理的に働きかけて関心を引き，次に行うべき行為に誘導する，という人とのインタラクションを繰り返し行うことで，人の身体的な学びを促す，すなわち，人の行動変容を促すことができるという可能性があります．</p>

<p>ソーシャブルなロボットの次のステップとしての，ソーシャブルなモノ（Sociable Things）は，意義のある研究領域であり，有力な候補です．ロボットの実装やそれに対する利便性というロボット工学的なアプローチだけでなく，行動変容などの認知心理学的，医療的議論も必要な，学際的研究テーマとなるでしょう．既に，ユーザの疲労を検知してアクションを起こす「ワークライフバランスキーボード」をはじめとする，いくつかのプロジェクトがスタートしていますが，さらなる研究的発展が期待されています．</p>

<hr />

<p><strong>各自が得意の分野でエキスパートに</strong></p>

<p>研究会では，大学院プロジェクト（ユビキタスコンピューティング&amp;ネットワーキングプロジェクト）とも連携し，調査，グループディスカッションといった研究活動を通して，論点の洗い出しを行い，メンバ個々に問題を設定，それらを解決するための手法を探ります．</p>

<p>各メンバには，学期中にこれら一連のサイクルを経験してもらいますが，特に，徳田・高汐合同研究会が所有するユビキタス情報空間実験室である，SSLab. や Smart LivingRoom での実装・検証実験の経験を積むことで，実証的な議論の姿勢と，システム開発に必要な様々なスキルを学んでもらいます．</p>

<p>加えて，研究会のメンバには，1人1人が何かしらのエキスパートになってほしいと考えています．電子工作のエキスパート，特定のマイコンのエキスパート，機械工作のエキスパート，3D モデリングのエキスパート，機械学習のエキスパート，画像認識のエキスパート，制御系プログラミングのエキスパート等々，なんでも構いません．研究会活動の中で，各メンバが自分の得意分野を伸ばすだけでなく，メンバ同士がその得意分野をレクチャーし合うことでお互いのスキルアップを目指します．そのため，各自がテーマを設定し講師となるスキルアップセミナを，学期中に1回は開催してもらいます．</p>

<hr />

<p><strong>■ 感じるロボット／気付くロボット・・プロジェクト</strong></p>

<ul>
<li>
exo-NeuroNet： 行動意図に応じてアドホックに構築可能なロボットのための外部神経網
</li>
<li>
水中状況認識を可能とする水中パッシブセンサモジュール（水中ロボットのための人工スキン）
</li>
</ul>

<p><strong>■ やわらかい機械／ゆるいロボット・・プロジェクト</strong></p>

<ul>
<li>
Metamorphic Cloudbot： クラウド・ロボティックス・アーキテクチャをベースにしたパーソナル・ロボット・フレームワーク
</li>
<li>
空中浮遊型ゆるふわロボット
</li>
<li>
スマホのバッテリ残量を気にするだけのロボット
</li>
<li>
悶える自動改札
</li>
</ul>

<p><strong>■ 繋がるロボット／伝えるロボット・・プロジェクト</strong></p>

<ul>
<li>
多対多 R2H コミュニケーションのための特定話者認識と追跡手法
</li>
<li>
多対多 R2H コミュニケーションにおける会話コンテクスト制御
</li>
<li>
多対多 R2H インタラクションのためのネットワークリソースを活用した話題生成機構
</li>
<li>
多対多 R2H インタラクションにおけるパーソナル・スペース分析 ～Pepper に壁ドンはできるか～
</li>
<li>
一期一会 ～HRRH 遠隔アイスブレーキング～
</li>
<li>
ヒトと共に成長するロボット
</li>
</ul>

<p><strong>■ ロボットとの協調／ヒトの身体拡張・・プロジェクト</strong></p>

<ul>
<li>
アイコンタクトによるロボットと人の協調動作
</li>
<li>
ExAmp Robot ～微表情を増幅表現するパーソナルロボット～
</li>
<li>
ロボットの感覚を伝える装着型感覚ディスプレイ
</li>
<li>
exo-NeuroNet による生体神経網の空間的拡張と論理的身体感覚形成（Logical Body）
</li>
</ul></div>
    </div>
</div>





<script src="ui.js"></script>


</body>
</html>
